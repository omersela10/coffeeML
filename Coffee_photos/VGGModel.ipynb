{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the image-label mapping table\n",
    "mapping_table_path = \"updated_mapping_table.csv\"  # Update with the path to your mapping table\n",
    "mapping_table = pd.read_csv(mapping_table_path)\n",
    "\n",
    "# Drop rows with NaN values in labels\n",
    "mapping_table.dropna(subset=['crema', 'color_clarity', 'presentation', 'type_of_cup', 'type_of_coffee', 'served_way'], inplace=True)\n",
    "\n",
    "# Load and preprocess images\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "images_dir = \"augmented_images_folder\"  # Folder containing augmented images\n",
    "\n",
    "for index, row in mapping_table.iterrows():\n",
    "    image_name = row['image_name']\n",
    "    image_path = os.path.join(images_dir, image_name)\n",
    "    \n",
    "    # Attempt to read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Check if the image was loaded successfully\n",
    "    if image is None:\n",
    "        print(f\"Warning: Unable to load image '{image_name}'. Skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Resize the image to match input size of VGG16\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    \n",
    "    # Append the resized image to the list of images\n",
    "    images.append(image)\n",
    "    \n",
    "    # Append the labels to the list of labels\n",
    "    labels.append(row.drop('image_name').drop('is_relevant').values)  # Exclude 'image_name' and 'is_relevant' from labels\n",
    "\n",
    "# Convert lists of images to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Convert labels to one-hot encoded format using MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_encoded = mlb.fit_transform(labels)\n",
    "\n",
    "# Perform cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define lists to store evaluation results\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Iterate over cross-validation folds\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(images)):\n",
    "    print(f\"Training fold {fold + 1}/5\")\n",
    "    \n",
    "    # Split data into train and validation sets\n",
    "    X_train, X_val = images[train_index], images[val_index]\n",
    "    y_train, y_val = labels_encoded[train_index], labels_encoded[val_index]\n",
    "    \n",
    "    # Load pre-trained VGG16 model without top layers\n",
    "    base_model = VGG16(weights='imagenet', include_top=False)\n",
    "    \n",
    "    # Add custom top layers for classification\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(y_train.shape[1], activation='sigmoid')(x)  # Sigmoid for multi-label classification\n",
    "    \n",
    "    # Create final model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Freeze the pre-trained layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
    "    \n",
    "    # Evaluate the model on validation data\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "# Calculate average validation metrics\n",
    "avg_val_loss = np.mean(val_losses)\n",
    "avg_val_accuracy = np.mean(val_accuracies)\n",
    "\n",
    "print(f\"Average validation loss: {avg_val_loss}\")\n",
    "print(f\"Average validation accuracy: {avg_val_accuracy}\")\n",
    "\n",
    "# Save model weights\n",
    "model.save_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
